{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from scipy import sparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing \n",
    "def feature_select(p, X, feature_names):\n",
    "    if p == 1:\n",
    "        return X.toarray(), feature_names\n",
    "    else:\n",
    "        feature_count = int(X.shape[1] * p)\n",
    "        select_feature_index = [x[0] for x in (sorted(enumerate(X.sum(axis=0).tolist()[0]), key=lambda x: x[1], reverse=True))][:feature_count]\n",
    "        all_feature_index = [i for i in range(X.shape[1])]\n",
    "        feature_index = [i for i in all_feature_index if i not in select_feature_index]\n",
    "        new_x = np.delete(X.toarray(), feature_index, axis=1)\n",
    "        new_feature_names = [feature_names[i] for i in select_feature_index]\n",
    "        return new_x, new_feature_names\n",
    "\n",
    "def label_select(y, label_names):\n",
    "    b = []\n",
    "    new_label_names = [i for i in label_names]\n",
    "    for i in range(y.shape[1]):\n",
    "        if y[:, i].sum() <= 5:\n",
    "            b.append(i)\n",
    "            new_label_names.remove(label_names[i])\n",
    "    new_y = np.delete(y.toarray(), b, axis=1)\n",
    "    return new_y, new_label_names\n",
    "\n",
    "def get_most_related_nodes(y):\n",
    "    num_nodes=y.shape[1]\n",
    "    graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "    graph = graph_builder.transform(y)\n",
    "    related_nodes = {}\n",
    "    for edge, weight in graph.items():\n",
    "        related_nodes.setdefault(edge[0], []).append((edge[1], weight))\n",
    "        related_nodes.setdefault(edge[1], []).append((edge[0], weight))\n",
    "    return [max(related_nodes.get(node, [(node, 0.0)]), key=lambda x: x[1])[0] for node in range(num_nodes)]\n",
    "\n",
    "def Labeltype(X,y):\n",
    "    ImbalanceRatioMatrix,MeanIR,_=Imbalance(X,y)\n",
    "    DifferenceImbalanceRatioMatrix=[i-MeanIR for i in ImbalanceRatioMatrix]\n",
    "    MinLabelIndex=[]\n",
    "    MajLabelIndex=[]\n",
    "    count=0\n",
    "    for i in (DifferenceImbalanceRatioMatrix):\n",
    "        if i>0:\n",
    "            MinLabelIndex.append(count)\n",
    "        else:\n",
    "            MajLabelIndex.append(count)\n",
    "        count+=1\n",
    "    MinLabelName=[]\n",
    "    MajLabelName=[]\n",
    "    for i in MinLabelIndex:\n",
    "        MinLabelName.append(label_names[i][0])\n",
    "    for i in MajLabelIndex:\n",
    "        MajLabelName.append(label_names[i][0])\n",
    "    MinLabeldic=dict(zip(MinLabelIndex,MinLabelName))\n",
    "    MajLabeldic=dict(zip(MajLabelIndex,MajLabelName))\n",
    "    return MinLabeldic,MajLabeldic\n",
    "\n",
    "def Imbalance(X,y):\n",
    "    countmatrix=[]\n",
    "    for i in range(y.shape[1]):\n",
    "        count0=0\n",
    "        count1=0\n",
    "        for j in range(y.shape[0]):\n",
    "            if y[j,i]==1:\n",
    "                count1+=1\n",
    "            else:\n",
    "                count0+=1\n",
    "        countmatrix.append(count1)\n",
    "    maxcount=max(countmatrix)\n",
    "    ImbalanceRatioMatrix=[maxcount/i for i in countmatrix]\n",
    "    MaxIR=max(ImbalanceRatioMatrix)\n",
    "    MeanIR=sum(ImbalanceRatioMatrix)/len(ImbalanceRatioMatrix)\n",
    "    return ImbalanceRatioMatrix,MeanIR,countmatrix\n",
    "\n",
    "def CardAndDens(X,y):\n",
    "    cardmatrix=[]\n",
    "    for i in range(X.shape[0]):\n",
    "        count=0\n",
    "        for j in range(y.shape[1]):\n",
    "            if y[i,j]==1:\n",
    "                count+=1\n",
    "        cardmatrix.append(count)\n",
    "    Card=sum(cardmatrix)/len(cardmatrix)\n",
    "    Dens=Card/y.shape[1]\n",
    "    return Card,Dens\n",
    "\n",
    "def ImR(X,y):\n",
    "    Imr=[]\n",
    "    for i in range(y.shape[1]):\n",
    "        count0=0\n",
    "        count1=0\n",
    "        for j in range(y.shape[0]):\n",
    "            if y[j,i]==1:\n",
    "                count1+=1\n",
    "            else:\n",
    "                count0+=1\n",
    "        if count1<=count0:\n",
    "            Imr.append(count0/count1)\n",
    "        else:\n",
    "            Imr.append(count1/count0)\n",
    "    return Imr\n",
    "\n",
    "def compare_arrays( a, b):\n",
    "    num_common_ones = np.sum((a == 1) & (b == 1))\n",
    "    num_non_zeros = np.sum((a + b) > 0)\n",
    "    return num_common_ones / num_non_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Natrual neighbor\n",
    "def SearchNaN(dfX):\n",
    "    TH=dfX.shape[0]+1\n",
    "    NaN=[]\n",
    "    for k in range(1,dfX.shape[0]):\n",
    "        RKNN=[]\n",
    "        stopcount=0  \n",
    "        nbs=NearestNeighbors(n_neighbors=k+1,metric='euclidean',algorithm='kd_tree').fit(dfX)\n",
    "        euclidean,indices= nbs.kneighbors(dfX)\n",
    "        for i in range(dfX.shape[0]):\n",
    "            tem=[j for j in range(dfX.shape[0]) if i in indices[j,1:]]\n",
    "            RKNN.append(tem)\n",
    "        for q in RKNN:\n",
    "            if q == []:\n",
    "                stopcount=stopcount+1\n",
    "        if TH==stopcount:\n",
    "            break\n",
    "        else:\n",
    "            TH=stopcount \n",
    "    for i in range(dfX.shape[0]):\n",
    "        NaNi=[j for j in indices[i,1:].tolist() if j in RKNN[i]]\n",
    "        NaN.append(NaNi)\n",
    "    return NaN\n",
    "#  MLONC\n",
    "def MLONC(df1,df2,p):\n",
    "    most_related_nodes = get_most_related_nodes(np.array(df2)) \n",
    "    np.random.seed(10)\n",
    "    NewSample=int(df1.shape[0]*p)\n",
    "    MLONC_new_X=df1.copy(deep=True)\n",
    "    MLONC_target=df2.copy(deep=True)\n",
    "    TotalNaN=[]\n",
    "    MinLabeldic,MajLabeldic=Labeltype(np.array(df1),np.array(df2))\n",
    "    ImbalanceRatioMatrix,MeanIR,countmatrix=Imbalance(np.array(df1),np.array(df2))\n",
    "    Card,Dens=CardAndDens(np.array(df1),np.array(df2))\n",
    "    Imr=ImR(np.array(df1),np.array(df2))\n",
    "    meanImR=sum(Imr)/len(Imr)\n",
    "    minImR=[Imr[i] for i in MinLabeldic.keys()]\n",
    "    samplematrix=[int(i*NewSample/sum(minImR)) for i in minImR]\n",
    "    percount=0\n",
    "    noisesample=[]\n",
    "    dif=[]\n",
    "    for tail_label in MinLabeldic.keys():\n",
    "        pergenerate=samplematrix[percount]       \n",
    "        sub_index=list(df2[df2[MinLabeldic[tail_label]]==1].index)\n",
    "        dfX= df1[df1.index.isin(sub_index)].reset_index(drop = True)\n",
    "        dfy= df2[df2.index.isin(sub_index)].reset_index(drop = True)\n",
    "        new_X = np.zeros((pergenerate, dfX.shape[1]))\n",
    "        target = np.zeros((pergenerate, dfy.shape[1]))\n",
    "        if dfX.shape[0]==1:\n",
    "            continue\n",
    "        NaN=SearchNaN(dfX)\n",
    "        TotalNaN.append(sum([len(i) for i in NaN]))\n",
    "        W=[len(i) for i in NaN]\n",
    "        W=[elem for elem in W if elem != 0]\n",
    "        list1=[i for i in range(dfX.shape[0])]\n",
    "        list2=[index for index,value in enumerate(NaN) if value==[]] \n",
    "        for i in list2:\n",
    "            noisesample.append(sub_index[i])\n",
    "        list3=list(set(list1)-set(list2))\n",
    "        if len(list3)==0:\n",
    "            continue\n",
    "        sorted_tuples = sorted(zip(W, list3))\n",
    "        list1_sorted, list3 = zip(*sorted_tuples)\n",
    "        deletematrix=[]\n",
    "        for i in range(pergenerate):\n",
    "            seed=list3[i%len(list3)]\n",
    "            reference=np.random.choice(NaN[seed])\n",
    "            npseed=np.array(dfy.loc[seed])\n",
    "            npreference=np.array(dfy.loc[reference])\n",
    "            dist=compare_arrays(npseed, npreference)\n",
    "            for j in range(dfX.shape[1]):\n",
    "                rmd=np.random.random()\n",
    "                if feature_names[j][1]=='NUMERIC':  \n",
    "                    new_X[i,j] = dfX.iloc[seed,j] + rmd*(dfX.iloc[reference,j]-dfX.iloc[seed,j])\n",
    "                else:\n",
    "                    new_X[i,j]=dfX.iloc[seed,j] \n",
    "            difl=0\n",
    "            for j in range(dfy.shape[1]):\n",
    "                a=most_related_nodes[j]\n",
    "                if npseed[j]==npreference[j]:\n",
    "                    target[i,j]=dfy.iloc[seed,j]\n",
    "                elif npseed[a]==1 or target[i,a]==1:\n",
    "                    target[i,j]=1\n",
    "                    difl+=1\n",
    "                else:\n",
    "                    target[i,j]=0  \n",
    "                    difl+=1\n",
    "            dif.append(difl)\n",
    "        dfnew_X = pd.DataFrame(new_X,columns=[x[0] for x in feature_names])\n",
    "        dftarget = pd.DataFrame(target,columns=[y[0] for y in label_names])\n",
    "        MLONC_new_X=pd.concat([MLONC_new_X,dfnew_X], axis=0).reset_index(drop=True)\n",
    "        MLONC_target=pd.concat([MLONC_target,dftarget], axis=0).reset_index(drop=True)\n",
    "        percount+=1\n",
    "    return MLONC_new_X,MLONC_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, index, p=None):\n",
    "    Randomlist=[7,10,19,30,23]\n",
    "    Macro=[]\n",
    "    for i in Randomlist:       \n",
    "        k_fold = IterativeStratification(n_splits=2,order=1,random_state=i)\n",
    "        for train,test in k_fold.split(X,y):\n",
    "            classifier =BinaryRelevance(\n",
    "                classifier = DecisionTreeClassifier(random_state=20),\n",
    "                require_dense = [False, True]\n",
    "            )\n",
    "            if(index==1):\n",
    "                X1,y1=X[train],y[train]\n",
    "            else: \n",
    "                dfx=pd.DataFrame(X[train],columns=[x[0] for x in feature_names])\n",
    "                dfy=pd.DataFrame(y[train],columns=[x[0] for x in label_names])\n",
    "                new_X,new_y=MLONC(dfx,dfy,p)\n",
    "                X1,y1=np.array(new_X),np.array(new_y)\n",
    "            classifier.fit(X1,y1)\n",
    "            X2,y2=X[test],y[test]\n",
    "            ypred = classifier.predict(X2)\n",
    "            yprob=classifier.predict_proba(X2)\n",
    "            yprob=yprob.toarray()\n",
    "            Macro.append(metrics.f1_score(y2, ypred,average='macro'))\n",
    "    MacroF=sum(Macro)/len(Macro)\n",
    "    return MacroF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:undivided - exists, not redownloading\n",
      "Macro F1 score for baseline: 0.5509\n",
      "Macro F1 score for MLONC: 0.5649\n"
     ]
    }
   ],
   "source": [
    "def main(p):\n",
    "    index = 1\n",
    "    macro_f1 = training(X, y, index)\n",
    "    print(f\"Macro F1 score for baseline: {round(macro_f1, 4)}\")\n",
    "\n",
    "    index = 2\n",
    "    macro_f1 = training(X, y, index,p)\n",
    "    print(f\"Macro F1 score for MLONC: {round(macro_f1, 4)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "# choose dataset\n",
    "    X, y, feature_names, label_names = load_dataset('emotions', 'undivided')\n",
    "    X, feature_names = feature_select(1, X, feature_names)\n",
    "    y, label_names = label_select(y, label_names)\n",
    "# set sampling count p\n",
    "    main(p=0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
